{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from roboflow import Roboflow\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DAFFA PINJEM BUAT BACKUP\\\\TA GASS\\\\FIX\\\\Yolo'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = (os.getcwd())\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = './Defect-Coffee-Test/'\n",
    "target_dir = './Coffee-Test-Result/'\n",
    "predict_dir = './Predict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_files(directory):\n",
    "  for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    try:\n",
    "      if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)\n",
    "      elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "      print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "# Initialize API for coffee bean detection\n",
    "rf = Roboflow(api_key=\"IluK8shPQ2JbRq6f5FVM\")\n",
    "\n",
    "# Reference : https://universe.roboflow.com/coffe-dataset/coffee-beans-znwfe/model/2\n",
    "project = rf.workspace().project(\"coffee-beans-znwfe\")\n",
    "model = project.version(2).model\n",
    "\n",
    "# Reference : https://universe.roboflow.com/coffee-pqokc/coffee-beans-detection-test/model/5\n",
    "# project = rf.workspace().project(\"coffee-beans-detection-test\")\n",
    "# model = project.version(5).model\n",
    "confident = 20\n",
    "\n",
    "def coffee_detection(filename):\n",
    "  # infer on a local image\n",
    "  result = model.predict(f\"{source_dir}{filename}\", confidence=confident).json()\n",
    "\n",
    "  # visualize your prediction\n",
    "  # model.predict(f\"{source_dir}{filename}\", confidence=confident, overlap=overlap).save(f\"{target_dir}{filename}\")\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(num_classes):\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_ftrs, num_classes)  # Ganti num_classes dengan jumlah kelas dalam dataset Anda\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path):\n",
    "    model = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coffee Bean Roast Level Detection\n",
    "roast_label_list = ['Dark', 'Green', 'Light', 'Medium']\n",
    "roastlevel_path = 'resnet50-coffee-roast-level.pth'\n",
    "roastlevel_model = load_model(roastlevel_path)\n",
    "\n",
    "# Coffee Bean Defect Detection\n",
    "defect_label_list = [\"Defect\", \"Normal\"]\n",
    "defect_path = 'resnet50-coffee-defect.pth'\n",
    "defect_model = load_model(defect_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all_files(predict_dir)\n",
    "delete_all_files(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "file_images = os.listdir(source_dir)\n",
    "img_list = []\n",
    "\n",
    "for file_image in file_images:\n",
    "    result = coffee_detection(file_image)\n",
    "\n",
    "    # Open the image file\n",
    "    for index, predict in enumerate(result[\"predictions\"]):\n",
    "        img = Image.open(os.path.join(source_dir, file_image))\n",
    "\n",
    "        confidence = round(predict[\"confidence\"] * 100, 2)\n",
    "\n",
    "        # Set the crop region\n",
    "        x, y, width, height = predict[\"x\"], predict[\"y\"], predict[\"width\"], predict[\"height\"]\n",
    "        max_width = max(width, height)\n",
    "        crop_region = (x-(int(max_width/2)), y-(int(max_width/2)), x+(int(max_width/2)), y+(int(max_width/2)))\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_img = img.crop(crop_region)\n",
    "\n",
    "        # Save cropped image\n",
    "        cropped_filename = f\"{file_image.split('.')[0]}-{index}.jpg\"\n",
    "        cropped_img.save(f\"./Predict/{cropped_filename}\")\n",
    "        img_tuple = (cropped_filename, file_image, (x, y, width, height), confidence)\n",
    "        img_list.append(img_tuple)\n",
    "\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detection = []\n",
    "# loop through the images and make predictions\n",
    "for img_predict in img_list:\n",
    "    # load the image and apply the transformations\n",
    "    image = Image.open(os.path.join(predict_dir, img_predict[0]))\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # make a prediction\n",
    "    with torch.no_grad():\n",
    "        # Coffee Bean Defect Detection\n",
    "        defect_output = defect_model(image)\n",
    "        predicted_defect = np.argmax(defect_output.numpy())\n",
    "        defect_label = defect_label_list[predicted_defect.item()]\n",
    "\n",
    "        # Coffee Bean Roast Level Detection\n",
    "        # roast_output = roastlevel_model(image)\n",
    "        # predicted_roast = np.argmax(roast_output.numpy())\n",
    "        # roast_label = roast_label_list[predicted_roast.item()]\n",
    "\n",
    "        # Get image source\n",
    "        if not os.path.exists(os.path.join(target_dir, img_predict[1])):\n",
    "            img_result = cv2.imread(os.path.join(source_dir, img_predict[1]))\n",
    "        else:\n",
    "            img_result = cv2.imread(os.path.join(target_dir, img_predict[1]))\n",
    "\n",
    "        x, y, w, h = img_predict[2]\n",
    "\n",
    "        # Draw bounding box on the image\n",
    "        cv2.rectangle(img_result, (x - int(w/2), y - int(h/2)), (x + int(w/2), y + int(h/2)), (0, 0, 255), 2)\n",
    "\n",
    "        # Add label to the bounding box\n",
    "        cv2.putText(img_result, f\"{defect_label} {img_predict[3]}%\", (x - int(w/2), y - int(h/2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        # cv2.putText(img_result, f\"{roast_label} {img_predict[3]}%\", (x - int(w/2), y - int(h/2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Save the img_result with bounding box and label\n",
    "        cv2.imwrite(os.path.join(target_dir, img_predict[1]), img_result)\n",
    "\n",
    "        detect_tuple = (img_predict[0], img_predict[1], img_predict[2], img_predict[3],  defect_label)\n",
    "        # detect_tuple = (img_predict[0], img_predict[1], img_predict[2], img_predict[3], roast_label)\n",
    "\n",
    "        img_detection.append(detect_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detection = [list(item) for item in img_detection]\n",
    "for item in img_detection:\n",
    "    item[2] = list(item[2])\n",
    "\n",
    "with open('result.json', 'w') as f:\n",
    "    json.dump(img_detection, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
